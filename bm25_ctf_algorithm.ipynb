{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get discussion_list\n",
    "try:\n",
    "    cache_file = open('discussion_list3.json', 'r')\n",
    "    cache_contents = cache_file.read()\n",
    "    discussion_lists = json.loads(cache_contents)\n",
    "    cache_file.close()\n",
    "except:\n",
    "    print(\"something bad happens!\")\n",
    "    \n",
    "try:\n",
    "    cache_file = open('leetcode_questions.json', 'r')\n",
    "    cache_contents = cache_file.read()\n",
    "    leetcode_questions = json.loads(cache_contents)\n",
    "    cache_file.close()\n",
    "except:\n",
    "    print(\"something bad happens!\")\n",
    "    \n",
    "try:\n",
    "    cache_file = open('problem_descriptions.json', 'r')\n",
    "    cache_contents = cache_file.read()\n",
    "    problem_descriptions = json.loads(cache_contents)\n",
    "    cache_file.close()\n",
    "except:\n",
    "    print(\"something bad happens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25-CTF Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def savePickle(dictfile,filename):\n",
    "\tprint(\"saving....\")\n",
    "\tf=open(filename+\".pickle\",'wb')\n",
    "\tpickle.dump(dictfile,f)\n",
    "\tf.close()\n",
    "\n",
    "def loadPickle(filename):\n",
    "\tprint(\"loading....\")\n",
    "\tf=open(filename+\".pickle\",'rb')\n",
    "\tdictfile=pickle.load(f)\n",
    "\tf.close()\n",
    "\treturn dictfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading....\n"
     ]
    }
   ],
   "source": [
    "meta=loadPickle('meta_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading....\n"
     ]
    }
   ],
   "source": [
    "weighted_scores=loadPickle('weighted_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('documents_id.txt')\n",
    "lines=f.readlines()\n",
    "f.close()\n",
    "document_map={}\n",
    "for each in lines:\n",
    "    my_data=each.split(\"\\t\")\n",
    "    document_map[my_data[0]]=my_data[1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class bm25_ctf():                                            \n",
    "                                                                       \n",
    "    def __init__(self, k1 = 1.25, b = 0.9, k3 = 500):                                             \n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.k3 = k3                                      \n",
    "                                                                                 \n",
    "    def score_one(self, w,query_meta,meta,document_id):\n",
    "        k1 = self.k1\n",
    "        b = self.b\n",
    "        k3 = self.k3\n",
    "        #Fill your answer here\n",
    "        ictf=math.log(meta['total_terms']/meta['corpus_term_count'][w])\n",
    "        pidf=math.log(-(1-2**(-meta['corpus_term_count'][w]/meta['num_docs']))/(math.log(1-meta['doc_count'][w]/meta['num_docs']))+1)\n",
    "        idf=math.log((meta['num_docs']-meta['doc_count'][w]+0.5)/(meta['doc_count'][w]+0.5))\n",
    "        bidf=ictf*pidf*idf\n",
    "        tf=((k1+1)*meta['btf'][w][document_id])/(k1*(1-b+b*meta['doc_size'][document_id]/meta['avg_dl'])+meta['btf'][w][document_id])\n",
    "        qtf=((k3+1)*query_meta['query_term_weight'][w])/(k3+query_meta['query_term_weight'][w])\n",
    "        \n",
    "        res=bidf*tf*qtf\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def score(self,query_meta,document_id,meta):\n",
    "        words=set(query_meta['query_words']) & meta['doc_unique_terms'][document_id]\n",
    "        score=0\n",
    "        for w in words:\n",
    "            score+=self.score_one(w,query_meta,meta,document_id)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_score(query_meta,i,weighted_scores):\n",
    "    score=0\n",
    "    prog_lan_score=weighted_scores['prog_lan_score']\n",
    "    tag_score=weighted_scores['tag_score']\n",
    "    difficulty_score=weighted_scores['difficulty_score']\n",
    "    title_score=weighted_scores['title_score']\n",
    "    keywords_in_discussion=weighted_scores['keywords_in_discussion']\n",
    "    for t in tag_score:\n",
    "        if t in query_meta['query']:\n",
    "            if str(i) in tag_score[t]:\n",
    "                score+=tag_score[t][str(i)]*0.1\n",
    "        if t in query_meta['query']:\n",
    "            if str(i) in keywords_in_discussion[t]:\n",
    "                score+=keywords_in_discussion[t][str(i)]\n",
    "    for t in title_score:\n",
    "        if t in query_meta['query']:\n",
    "            if str(i) in title_score[t]:\n",
    "                score+=title_score[t][str(i)]\n",
    "\n",
    "    for w in query_meta['query'].split():\n",
    "        if w in weighted_scores['prog_lan_score']:\n",
    "            if i in weighted_scores['prog_lan_score'][w]:\n",
    "                score+=weighted_scores['prog_lan_score'][w][i]\n",
    "        if w in weighted_scores['difficulty_score']:\n",
    "            if str(i) in weighted_scores['difficulty_score'][w]:\n",
    "                score+=weighted_scores['difficulty_score'][w][str(i)]\n",
    "        elif w=='difficult':\n",
    "            if str(i) in weighted_scores['difficulty_score']['hard']:\n",
    "                score+=weighted_scores['difficulty_score']['hard'][str(i)]\n",
    "    \n",
    "    vote_score=weighted_scores['vote_score']\n",
    "    view_score=weighted_scores['view_score']\n",
    "    if str(i) in vote_score:\n",
    "        score+=vote_score[str(i)]*0.01+view_score[str(i)]*0.0001\n",
    "                \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_meta(query):\n",
    "    if 'dynamic programming' in query:\n",
    "        query+=' dp'\n",
    "    elif 'dp' in query:\n",
    "        query+=' dynamic programming '\n",
    "        \n",
    "    if query in query_logs:\n",
    "        return query_logs[query]\n",
    "    else:\n",
    "        query_words=query.lower().split()\n",
    "              \n",
    "        query_length=len(query_words)\n",
    "        query_term_weight={}\n",
    "        for qw in query_words:\n",
    "            if qw not in query_term_weight:\n",
    "                query_term_weight[qw]=1\n",
    "            else:\n",
    "                query_term_weight[qw]+=1\n",
    "        \n",
    "\n",
    "        query_meta={}\n",
    "        query_meta['query_length']=query_length\n",
    "        query_meta['query_term_weight']=query_term_weight\n",
    "        query_meta['query_words']=query_words\n",
    "        query_meta['query']=query\n",
    "        query_meta['related_query']=[]\n",
    "        query_logs[query]=query_meta\n",
    "        return query_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def do_search(query,meta,weighted_scores):\n",
    "    d_scores={}\n",
    "    query_meta=get_query_meta(query)\n",
    "    print(\"query:\",query_meta['query'])\n",
    "    print(\"result:\")\n",
    "    for i in range(1,meta['num_docs']):      \n",
    "        d_scores[i]=[ranker.score(query_meta,i,meta)+get_weighted_score(query_meta,i,weighted_scores)]\n",
    "    my_frame=pd.DataFrame.from_dict(d_scores).T\n",
    "    my_frame.columns=['scores']\n",
    "    my_frame=my_frame.sort_values(by='scores',ascending=False)\n",
    "    print(my_frame.head(10))\n",
    "#     print(\"related query:\")\n",
    "#     RQ_len=5\n",
    "#     if len(query_meta['related_query'])<5:\n",
    "#         RQ_len=len(query_meta['related_query'])       \n",
    "#     for i in range(RQ_len):\n",
    "#         print(query_meta['related_query'][i], end=\" \")\n",
    "    return d_scores,my_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logs={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker=bm25_ctf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"difficult question with dynamic programming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: difficult question with dynamic programming dp\n",
      "result:\n",
      "          scores\n",
      "1262  222.278301\n",
      "1990  200.550230\n",
      "36    142.341665\n",
      "529   141.444494\n",
      "566   140.646702\n",
      "181   140.145225\n",
      "611   139.456499\n",
      "567   138.108750\n",
      "846   137.966358\n",
      "131   137.754428\n"
     ]
    }
   ],
   "source": [
    "d_scores,my_frame=do_search(query,meta,weighted_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1262, 1990, 36, 529, 566, 181, 611, 567, 846, 131]"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_=list(my_frame.head(10).index.values)\n",
    "id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++ dynamic programming, O(N^3), 32 ms, with comments\n",
      "https://leetcode.com/problems/burst-balloons/discuss/76232/C%2B%2B-dynamic-programming-O(N3)-32-ms-with-comments\n",
      "Why does Greedy solution work for this; why not Dynamic Programming ?\n",
      "https://leetcode.com/problems/ipo/discuss/142490/Why-does-Greedy-solution-work-for-this-why-not-Dynamic-Programming\n",
      "Easy DP Java Solution with detailed Explanation\n",
      "https://leetcode.com/problems/regular-expression-matching/discuss/5651/Easy-DP-Java-Solution-with-detailed-Explanation\n",
      "7-10 lines C++ Solutions with Detailed Explanations (O(m*n) time and O(m) space)\n",
      "https://leetcode.com/problems/distinct-subsequences/discuss/37316/7-10-lines-C%2B%2B-Solutions-with-Detailed-Explanations-(O(m*n)-time-and-O(m)-space)\n",
      "Is it Best Solution with O(n), O(1).\n",
      "https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/discuss/39611/Is-it-Best-Solution-with-O(n)-O(1).\n",
      "Linear runtime and constant space solution\n",
      "https://leetcode.com/problems/wildcard-matching/discuss/17810/Linear-runtime-and-constant-space-solution\n",
      "My solution does not need a table for palindrome, is it right ? It uses only O(n) space.\n",
      "https://leetcode.com/problems/palindrome-partitioning-ii/discuss/42198/My-solution-does-not-need-a-table-for-palindrome-is-it-right-It-uses-only-O(n)-space.\n",
      "A clean DP solution which generalizes to k transactions\n",
      "https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/discuss/39608/A-clean-DP-solution-which-generalizes-to-k-transactions\n",
      "A Concise DP Solution in Java\n",
      "https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iv/discuss/54113/A-Concise-DP-Solution-in-Java\n",
      "My O(n) solution using a stack\n",
      "https://leetcode.com/problems/longest-valid-parentheses/discuss/14126/My-O(n)-solution-using-a-stack\n"
     ]
    }
   ],
   "source": [
    "for each in id_:\n",
    "    qid,did=document_map[str(each)].split(\"-\")\n",
    "    print(discussion_lists[str(qid)][int(did)]['discussion_title'])\n",
    "    print(discussion_lists[str(qid)][int(did)]['discussion_link'])\n",
    "#     print(leetcode_questions[str(qid)]['problem_title'])\n",
    "#     print(leetcode_questions[str(qid)]['problem_url'])\n",
    "    \n",
    "#     print(leetcode_questions[str(qid)])\n",
    "#     print(discussion_lists[str(qid)][int(did)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add some feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update_word_list(item_list,threshold=3):\n",
    "    word_list=[]\n",
    "    for i in item_list:\n",
    "        for w in meta['doc_unique_terms'][i]:\n",
    "            important_score=meta['btf'][w][i]*(1/meta['doc_count'][w])\n",
    "            if important_score>threshold:\n",
    "                word_list.append(w)\n",
    "                print(w,important_score)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for feedback\n",
    "def query_meta_update(query_meta,word_lists,update_rate=1):\n",
    "    \n",
    "    for w in word_lists:\n",
    "        query_meta['query_words'].append(w)\n",
    "        if w not in query_meta['query_term_weight']:\n",
    "            query_meta['query_term_weight'][w]=update_rate\n",
    "        else:\n",
    "            query_meta['query_term_weight'][w]+=update_rate\n",
    "        query_meta['query_length']+=update_rate*len(word_lists)\n",
    "        \n",
    "        query_meta['related_query'].append(w)\n",
    "    \n",
    "    return query_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good 4.0\n",
      "2018 4.0\n",
      "haha 4.0\n",
      "luck 4.0\n"
     ]
    }
   ],
   "source": [
    "word_list=get_update_word_list(item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_logs[query]=query_meta_update(get_query_meta(query),word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: hello baby * good 2018 haha luck * \n",
      "result:\n",
      "0 0.37061128130176607\n",
      "1 0\n",
      "2 0.1938100058015275\n",
      "3 2.2973177085906604\n",
      "4 9.189270834362642\n",
      "related query:\n",
      "hello baby "
     ]
    }
   ],
   "source": [
    "d_scores=do_search(query,meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
